"""
Narration script for: color-perception
Generated: 2026-02-13
Duration: ~240 seconds
"""

SCRIPT = {
    "intro": """Imagine you're looking at a vibrant sunset, but what if I told you that having more color receptors in your eyes doesn't automatically give you a richer experience? That's the paradox we're diving into today. We'll explore how the number of sensory channels an organism has doesn't directly translate to the dimensionality of its conscious perception. This is where Donald Hoffman's conscious-agent formalism comes in, using Markov kernels on polytopes to model possible consciousnesses. Join me as we uncover why more isn't always better in the world of color perception.""",
    "bottleneck": """Let's start with the bottleneck theorem. Picture this: mantis shrimp have twelve different types of color receptors, far more than humans' three. Yet, behaviorally, they don't show the fine-grained color discrimination you'd expect. Why? Because the effective dimensionality of perception isn't just about receptor count. It's limited by how the nervous system processes those signals. Neural processing acts like a bottleneck, capping how many independent perceptual dimensions emerge from those raw receptor inputs. This means the richness of experience depends on both the input channels and the downstream neural architecture that interprets them.""",
    "compression": """Now, let's introduce the Markov polytope and the compression ratio. In Hoffman's framework, an agent with n experiential states has its dynamics living in a Markov polytope of dimension n times n minus 1. Think of this as the geometric space of all possible ways conscious states can transition. For color, n roughly corresponds to the number of receptor types, k. So for humans with k equals 3, the polytope has dimension 6. But the key insight is efficiency: how many just-noticeable-differences, or JNDs, does the organism actually achieve across its spectrum? The efficiency ratio eta equals JNDs divided by k times k minus 1. This measures how well the organism fills its available polytope space with real perceptual distinctions.""",
    "examples": """Let's look at some cross-species examples to make this concrete. Humans, with just three cone types, achieve around 150 spectral JNDs from a polytope of dimension 6, giving an eta of about 25. That's high efficiency through deep cortical processing. Mantis shrimp, with twelve receptor classes and a polytope dimension of 132, only manage about 12 discriminable bins, for an eta around 0.09. They use fast, shallow interval decoding instead of opponent processing. Tetrachromats, like some women with a fourth cone type, have a polytope of dimension 12. If they gain richer perception, it's only if their neural processing scales to exploit those extra dimensions. Otherwise, they might just get a coarser experience.""",
    "prediction": """Here's the falsifiable prediction: across different species, the efficiency ratio eta should show a clear inverse relationship with receptor count k. Organisms with more receptor types will have systematically lower eta values. Vertebrates with few receptors and deep recurrence should cluster at high eta above 10, while arthropods with many receptors and shallow processing should be below 1. This inverse scaling hasn't been tested before, but existing data from psychophysics and genetics can verify it today. If true, it would support Hoffman's polytope framework as more than just mathematical abstraction.""",
    "implications": """What does this mean for consciousness and AI? This tests Hoffman's theory by showing whether his geometric formalism predicts real perceptual performance across species. If organisms systematically underuse their polytopes based on receptor count, it suggests the polytope isn't just a metaphysical space but has empirical relevance. For artificial sensory systems, the lesson is clear: adding more sensor channels without scaling up the processing depth just wastes resources. It shifts you into a fast but coarse regime. AI designers should scale neural architecture before adding more sensors, following the decision rule: when eta drops below about 1, processing depth limits matter more than channel count.""",
    "recap": """Let's recap the key takeaways. More color receptors don't automatically mean richer perception. The effective dimensionality depends on neural processing limits, captured by the efficiency ratio eta: JNDs divided by k times k minus 1. Across species, eta inversely scales with receptor count, predicting that mantis shrimp waste most of their polytope while humans fill theirs efficiently. This bridges Hoffman's consciousness formalism with sensory ecology, offering a testable prediction. For AI and consciousness research, it reminds us that experience requires both broad inputs and deep processing to truly expand the space of possible perceptions.""",
}
